{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# 부하 원본 데이터 경로\n",
    "file_path = '2020_5E_load_cleaned.csv'\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'datetime' column to datetime format\n",
    "data['datetime'] = pd.to_datetime(data['datetime'])\n",
    "\n",
    "# Extract the day of the week from the 'datetime' column\n",
    "data['day_of_week'] = data['datetime'].dt.day_name()\n",
    "\n",
    "# Group the data by 'day_of_week' and apply linear interpolation for each group\n",
    "grouped_data = data.groupby('day_of_week')\n",
    "\n",
    "# Fill missing values using linear interpolation for each group\n",
    "for name, group in grouped_data:\n",
    "    data.loc[group.index, 'load'] = group['load'].interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated dataset to a new CSV file\n",
    "output_file_path = '2020_5E_load_cleaned_interpolated.csv'\n",
    "data.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('2020_5E_load_cleaned_interpolated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터 생성\n",
    "def data_gen(seed,sig):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    time_intervals = [\n",
    "        (0, 10000, 250, 300),\n",
    "        (10000, 20000, 300, 400),\n",
    "        (20000, 30000, 450, 700),\n",
    "        (30000, 40000, 700, 800),\n",
    "        (40000, 50000, 800, 600),\n",
    "        (50000, 60000, 600, 400),\n",
    "        (60000, 70000, 400, 750),\n",
    "        (70000, 80000, 750, 450),\n",
    "        (80000, 86400, 450, 350),\n",
    "    ]\n",
    "\n",
    "    time_points = np.arange(0, 86400, 300)\n",
    "    power_usage = []\n",
    "\n",
    "    for start, end, min_power, max_power in time_intervals:\n",
    "        mask = (time_points >= start) & (time_points < end)\n",
    "        power_usage.extend(np.random.uniform(min_power, max_power, mask.sum()))\n",
    "    power_usage = np.array(power_usage)\n",
    "    power_usage_smoothed = gaussian_filter1d(power_usage, sigma=sig)\n",
    "    return power_usage_smoothed\n",
    "\n",
    "# Load the CSV file\n",
    "def load_data(data):\n",
    "    data = pd.DataFrame(data)\n",
    "    data = data.reset_index(drop=False)\n",
    "    data.columns = ['Index', 'Power_Usage']\n",
    "    return data\n",
    "\n",
    "# Normalize the data to 288 points (5-minute intervals over 24 hours)\n",
    "def normalize_data(data, num_points=288):\n",
    "    new_index = np.linspace(1, data['Index'].max(), num_points)\n",
    "    interp_func = interp1d(data['Index'], data['Power_Usage'], kind='linear')\n",
    "    expanded_data = interp_func(new_index)\n",
    "    return new_index, expanded_data\n",
    "\n",
    "# Calculate the total power usage for the normalized dataset\n",
    "def calculate_total_usage(expanded_data):\n",
    "    return np.sum(expanded_data)\n",
    "\n",
    "# Generate 5-minute interval power usage data given a total daily usage\n",
    "def generate_power_usage(normalized_pattern, total_daily_usage):\n",
    "    return normalized_pattern * total_daily_usage\n",
    "\n",
    "# Plot the original and normalized data for comparison\n",
    "def plot_data(original_index, original_data, new_index, expanded_data, predicted_usage=None):\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(original_index, original_data, label='Original Data')\n",
    "    plt.plot(new_index, expanded_data, label='Interpolated Data (288 points)', linestyle='--')\n",
    "    if predicted_usage is not None:\n",
    "        plt.plot(new_index, predicted_usage, label=f'Predicted Usage (Total = {np.sum(predicted_usage)})', linestyle='-.')\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Power Usage')\n",
    "    plt.legend()\n",
    "    plt.title('Power Usage Data')\n",
    "    plt.show()\n",
    "\n",
    "# Main function to process the data and generate usage predictions\n",
    "def main(smoothed_data, load):\n",
    "    data = load_data(smoothed_data)\n",
    "    original_index, original_data = data['Index'], data['Power_Usage']\n",
    "    new_index, expanded_data = normalize_data(data)\n",
    "    total_usage = calculate_total_usage(expanded_data)\n",
    "    normalized_pattern = expanded_data / total_usage\n",
    "    predicted_usage = generate_power_usage(normalized_pattern, total_daily_usage)\n",
    "    #plot_data(original_index, original_data, new_index, expanded_data, predicted_usage)\n",
    "\n",
    "    # Step 1: Fit a Polynomial Model\n",
    "    X = data['Index'].values.reshape(-1, 1)\n",
    "    y = data['Power_Usage'].values\n",
    "    # Degree of the polynomial\n",
    "    degree = 6\n",
    "    # Create polynomial features\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    # Fit the polynomial model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_poly, y)\n",
    "\n",
    "    # Generate 288 time points for a day (5-minute intervals)\n",
    "    # time_points = np.linspace(1, 227, 288).reshape(-1, 1)\n",
    "    # time_points_poly = poly.transform(time_points)\n",
    "    # Predict the values\n",
    "    predicted_values = model.predict(X_poly)\n",
    "    # Step 2: Add Noise to the Predicted Values\n",
    "    noise_level = 0.2  # Adjust the noise level as needed\n",
    "    noise = np.random.normal(0, noise_level, predicted_values.shape)\n",
    "    noisy_values = predicted_values + noise\n",
    "\n",
    "    # Step 3: Normalize the Noisy Values\n",
    "    normalized_noisy_values = noisy_values / noisy_values.sum()\n",
    "    generated_load_data = normalized_noisy_values * load\n",
    "    return generated_load_data #predicted_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [00:00<00:00, 784.00it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "data_list = np.empty((0, 1))\n",
    "total_daily_usage = 1000\n",
    "\n",
    "for i in tqdm(range(len(data))):\n",
    "    date, load, day = data.iloc[i]\n",
    "    #generate_power_usage_pattern(load)\n",
    "    gen_load = main(data_gen(42,15), load)\n",
    "    gen_load = pd.DataFrame(gen_load, columns=['Load'])\n",
    "    #start_time = pd.Timestamp(date) # 시작 날짜와 시간\n",
    "    #time_intervals = pd.date_range(start=start_time, end=start_time + pd.Timedelta(days=1) - pd.Timedelta(minutes=5), freq='5T')\n",
    "    #time_df = pd.DataFrame(time_intervals, columns=['DateTime'])\n",
    "    data_list = np.append(data_list, gen_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = pd.DataFrame(data_list)\n",
    "data_list.to_csv('2020_load_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# CSV 파일을 읽어 들임\n",
    "df = pd.read_csv('2020_load_data.csv')  # 'your_file.csv'는 CSV 파일의 경로로 변경해야 함\n",
    "\n",
    "# 시작 시간과 종료 시간 설정\n",
    "start = datetime(2020, 1, 1)\n",
    "end = datetime(2020, 12, 31, 23, 55)\n",
    "\n",
    "# 5분 간격으로 시간 생성\n",
    "times = pd.date_range(start, end, freq='5T')\n",
    "\n",
    "# 데이터프레임의 행 수와 시간 범위의 길이를 비교하여 확인\n",
    "if len(df) > len(times):\n",
    "    raise ValueError(\"CSV 파일의 행 수가 시간 범위의 길이보다 많습니다.\")\n",
    "else:\n",
    "    # 시간을 새로운 열로 추가\n",
    "    df['DateTime'] = times[:len(df)]\n",
    "\n",
    "# 변경된 데이터프레임을 새 CSV 파일로 저장\n",
    "df.to_csv('updated_file.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
